First, the program will crawl the website, specifically the navigation menu tabs, and goes bfs up to depth 2/3, then computes a NxN markov matrix (N = number of pages crawled) where (r,c) represents whether page representing row r is accessible from the page representing column c, normalized so that the sum of each column is 1. Next, from this markov matrix the program will compute the pagerank, leaving the final Nx1 array as a probability vector. Then, a loop will begin so that as long as a goal is inputted, a semantic similarity function will iterate through the N pages and compute the similarity between the goal and each page's title & snippet (through a dictionary). Then augment the semantic similarity to the pagerank array (with 95/5 weighting) to rank the most promising pages on the website to achieve the goal.
